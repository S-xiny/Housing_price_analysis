{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56015e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "url ='''https://tj.lianjia.com/xiaoqu/heping/?from=recpage1 23,\n",
    "https://tj.lianjia.com/xiaoqu/nankai/?from=recpage1 25,\n",
    "https://tj.lianjia.com/xiaoqu/hexi/?from=recpage1 23,\n",
    "https://tj.lianjia.com/xiaoqu/hebei/?from=recpage1 17,\n",
    "https://tj.lianjia.com/xiaoqu/hedong/?from=recpage1 19,\n",
    "https://tj.lianjia.com/xiaoqu/hongqiao/?from=recpage1 11,\n",
    "https://tj.lianjia.com/xiaoqu/xiqing/?from=recpage1 17,\n",
    "https://tj.lianjia.com/xiaoqu/beichen/?from=recpage1 13,\n",
    "https://tj.lianjia.com/xiaoqu/dongli/?from=recpage1 15,\n",
    "https://tj.lianjia.com/xiaoqu/jinnan/?from=recpage1 12,\n",
    "https://tj.lianjia.com/xiaoqu/tanggu/?from=recpage1 18,\n",
    "https://tj.lianjia.com/xiaoqu/kaifaqutj/?from=recpage1 5,\n",
    "https://tj.lianjia.com/xiaoqu/wuqing/?from=recpage1 15,\n",
    "https://tj.lianjia.com/xiaoqu/binhaixinqu/?from=recpage1 14,\n",
    "https://tj.lianjia.com/xiaoqu/baodi/?from=recpage1 7,\n",
    "https://tj.lianjia.com/xiaoqu/jizhou/?from=recpage1 10,\n",
    "https://tj.lianjia.com/xiaoqu/haihejiaoyuyuanqu/?from=recpage1 2,\n",
    "https://tj.lianjia.com/xiaoqu/jinghai/?from=recpage1 9\n",
    "'''\n",
    "\n",
    " '''\n",
    "u = url_lst[1].split(' ')[0]\n",
    "lst = []\n",
    "n = 1\n",
    "for page in range(1,n+1):\n",
    "    u = u.replace('\\n','')\n",
    "    u = u.split(r'/?')[0] + '/pg' + '%i'%page + '/?' + u.split('/?')[1]\n",
    "ips = None\n",
    "ri = requests.get(url=u,headers = dic_h, cookies = dic_c,proxies=ips,timeout = 3)\n",
    " '''  \n",
    "def get_urls(urli,n):\n",
    "    '''\n",
    "    功能：分页网址url采集\n",
    "    n:页面参数\n",
    "    urli:网址\n",
    "    结果：得到分页网址list\n",
    "    '''\n",
    "    lst = []\n",
    "    for page in range(1,n+1):\n",
    "        ui = u.replace('\\n','')\n",
    "        ui = urli.split('/?')[0] + '/pg' + '%i'%page + '/?' + urli.split('/?')[1]\n",
    "        lst.append(ui)\n",
    "    return lst\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#解析页面\n",
    "def get_dataurls(ui,d_h,d_c,ips):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ui :    分页网址.\n",
    "    d_h :  user-agent信息.\n",
    "    d_c :  cookies信息\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    列表网址.\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        ri = requests.get(url=ui,headers = d_h, cookies = d_c,proxies=ips,timeout = 3)\n",
    "    except:\n",
    "        try:\n",
    "            ri = requests.get(url=ui,headers = d_h, cookies = d_c,proxies=ips,timeout = 3)\n",
    "        except:\n",
    "            print('request failed 2 times')\n",
    "    #访问页面\n",
    "    soupi = BeautifulSoup(ri.text,'lxml')\n",
    "    ul = soupi.find('ul',class_=\"listContent\")\n",
    "    lis = ul.find_all('li')\n",
    "    lst = []\n",
    "    for li in lis:\n",
    "        lst.append(li.find('a')['href'])\n",
    "    return lst\n",
    "\n",
    "'''\n",
    "ri = requests.get(url = urllst2[:1][0], headers = dic_h, cookies = dic_c, verify=False, proxies=None, timeout=3)\n",
    "soupi = BeautifulSoup(ri.text,'lxml')\n",
    "dic = {}#空字典存储数据  \n",
    "dic['单价'] = soupi.find('span',class_=\"xiaoquUnitPrice\").text\n",
    "dic['小区名称'] = soupi.find('div',class_=\"detailHeader fl\").h1.text   \n",
    "'''\n",
    "\n",
    "def get_data(ui,d_h,d_c,ips):\n",
    "    '''\n",
    "    \n",
    "\n",
    " Parameters\n",
    "    ----------\n",
    "    ui :    分页网址.\n",
    "    d_h :  user-agent信息.\n",
    "    d_c :  cookies信息\n",
    "\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        proxies = None\n",
    "        ri = requests.get(url = ui, headers = d_h, cookies = d_c, verify=False, proxies=ips, timeout=3)\n",
    "    except:\n",
    "    # logdebug('requests failed one time')\n",
    "        try:\n",
    "            proxies = None\n",
    "            ri = requests.get(url = ui, headers = d_h, cookies = d_c, verify=False, proxies=ips, timeout=3)\n",
    "        except:\n",
    "            # logdebug('requests failed two time')\n",
    "            print('requests failed two time')\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    soupi = BeautifulSoup(ri.text,'lxml')\n",
    "    dic = {}#空字典存储数据  \n",
    "    dic['单价'] = soupi.find('span',class_=\"xiaoquUnitPrice\").text\n",
    "    dic['小区名称'] = soupi.find('div',class_=\"detailHeader fl\").h1.text   \n",
    "    return dic\n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "def get_proxies(p_User,p_Pass,p_Host,p_Port):\n",
    "    '''\n",
    "    生成动态ip函数\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_Usermp_Pass :\n",
    "        设置代理服务器.\n",
    "    p_Host,p_Port : \n",
    "        代理服务器验证信息\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ip\n",
    "    \n",
    "    '''\n",
    "    proxyMeta = \"http://%(user)s:%(pass)s@%(host)s:%(port)s\" % {\n",
    "        \"host\" : p_Host,\n",
    "        \"port\" : p_Port,\n",
    "        \"user\" : p_User,\n",
    "        \"pass\" : p_Pass,\n",
    "    }\n",
    "    ips = {\n",
    "        \"http\"  : proxyMeta,\n",
    "        \"https\" : proxyMeta,\n",
    "    }\n",
    "    return ips\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #设置爬取多少页\n",
    "    \n",
    "    url_lst = url.strip().split(',')\n",
    "    url_u = []\n",
    "    for str in url_lst:\n",
    "        url_u.append(str.split(' '))\n",
    "    ip_dic = None\n",
    "    #设置代理ip\n",
    "#    ip_dic = get_proxies('123',\n",
    "#                         '123',\n",
    "#                         'http-dyn.abuyun.com',\n",
    "#                         '9020') \n",
    "\n",
    "    urllst1 = []\n",
    "    for url_p in url_u:\n",
    "        lst_test = get_urls(url_p[0],int(url_p[1]))\n",
    "        urllst1.extend(lst_test)\n",
    "\n",
    "    #u1 = urllst1[0]\n",
    "    dic_h = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36 Edg/88.0.705.81'}\n",
    "    dic_c = {}\n",
    "    cookies = '''lianjia_uuid=76645c73-49a1-438c-95c2-ee28cb500d5d; UM_distinctid=177eb577f602a6-024a3d39254076-7a667166-144000-177eb577f61680; _smt_uid=603c3f5c.25536a6d; _jzqy=1.1614561116.1614561116.1.jzqsr=baidu|jzqct=%E9%93%BE%E5%AE%B6.-; _ga=GA1.2.1136075548.1614561118; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%22177eb5781e6324-03916fdd886ac6-7a667166-1327104-177eb5781e73ab%22%2C%22%24device_id%22%3A%22177eb5781e6324-03916fdd886ac6-7a667166-1327104-177eb5781e73ab%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_referrer%22%3A%22%22%2C%22%24latest_referrer_host%22%3A%22%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%2C%22%24latest_utm_source%22%3A%22baidu%22%2C%22%24latest_utm_medium%22%3A%22pinzhuan%22%2C%22%24latest_utm_campaign%22%3A%22wybeijing%22%2C%22%24latest_utm_content%22%3A%22biaotimiaoshu%22%2C%22%24latest_utm_term%22%3A%22biaoti%22%7D%7D; _gid=GA1.2.867559070.1614651456; _jzqx=1.1614653279.1614675326.3.jzqsr=tj%2Elianjia%2Ecom|jzqct=/ershoufang/.jzqsr=tj%2Elianjia%2Ecom|jzqct=/ershoufang/; select_city=120000; lianjia_ssid=4b565a7f-28f0-4920-a381-69def72e8786; Hm_lvt_9152f8221cb6243a53c83b956842be8a=1614561141,1614651453,1614739422; CNZZDATA1253477585=1713710079-1614651050-%7C1614737852; CNZZDATA1254525948=1116885174-1614649764-%7C1614736165; CNZZDATA1255633284=80640280-1614649701-%7C1614736106; _jzqa=1.4025737189718715000.1614561116.1614675326.1614739423.6; _jzqc=1; _jzqckmp=1; _qzjc=1; CNZZDATA1255604082=979779749-1614649773-%7C1614739533; login_ucid=2000000156212651; lianjia_token=2.0012573cfd739dccba03fa15ccc218d43b; lianjia_token_secure=2.0012573cfd739dccba03fa15ccc218d43b; security_ticket=q9C8qQhDhwnSb/CQpsneR1kbrQqZ9Az/xHp18h5SKeO7F1TOViWP6fJbYJOQkNrdBitCypzmMOHL9doPLErTpqO74eiF1a9m4Xg6oWUdT6ZzqoWcKlh/fetCxElWI2CqQwVVimhItINdBuCDsuZbKbolon7R18ED0mWUHQ/O0P0=; Hm_lpvt_9152f8221cb6243a53c83b956842be8a=1614740786; _jzqb=1.6.10.1614739423.1; _qzja=1.693703322.1614651453707.1614675326242.1614739422909.1614740190787.1614740785929.0.0.0.21.5; _qzjb=1.1614739422909.6.0.0.0; _qzjto=6.1.0; srcid=eyJ0Ijoie1wiZGF0YVwiOlwiYmQ0NjJmNjU1NjZmNzE0ODczOGIzZDgwYzFiYTg2YmE0YzI1Y2E3MjRiZWE0ODkyNWE2M2FiOGNiNTRiZjQ1YTMwMzkwYTk4M2Y1YzI1YmFhMDM2YTUxNzk5OWVjOGRhMDhjYWMyODk4NDAzMzI4OTFjNjhkNTk1ZGRkZTIxMzRkYWRkZDdkNWZjZTUyMWYyOWZlMDM3ODhlNjhiMzVlMTE2MzhlZGEyYjA2ZjA5ZjE1NzMxYjFjMTQzNTM1NzZmZDQ4YjZmOTc1YmVjNmRiODNiYmE3MGU0MTdlZTkxMzJmZDI0NTYyOTg0Njc1YmQyMGI0NDRhYmM5ZThhOGE0MTQ2ZTU5MTMzMjc3N2E4MTcxZmQ5NDZlOWM3NTJkZGM1MDFhZmU3OGNhY2ZiYTk0MWY2MjdkMDYyZDAwMjU0YzcwODBlYjYwYWViYTgxZWEwZTIxZDc4ZTQzN2E0Mjk2M1wiLFwia2V5X2lkXCI6XCIxXCIsXCJzaWduXCI6XCJmYzQ0ZWNmNVwifSIsInIiOiJodHRwczovL3RqLmxpYW5qaWEuY29tL2Vyc2hvdWZhbmcvcGcxLyIsIm9zIjoid2ViIiwidiI6IjAuMSJ9'''\n",
    "    for i in cookies.split('; '):\n",
    "        dic_c[i.split('=')[0]] = i.split('=')[1]\n",
    "        #获取agent cookies\n",
    "        \n",
    "    urllst2 = []\n",
    "\n",
    "#得到每个房子的网址\n",
    "    for u in urllst1:\n",
    "        try:\n",
    "            urllst2.extend(get_dataurls(u, dic_h, dic_c,ip_dic))\n",
    "            print('成功采集页面信息，成功采集%i条数据' %(len(urllst2)))\n",
    "        except:\n",
    "            print('获取页面信息失败，分页网址位:',u)\n",
    "       # print(urllst2)  \n",
    "      \n",
    "#获取信息  \n",
    "    errorlst = []    \n",
    "    datalst = []\n",
    "    for u in urllst2:\n",
    "        try:\n",
    "            datalst.append(get_data(u,dic_h,dic_c,ip_dic))\n",
    "            print('数据采集成功，总共采集%i条数据' %len(datalst))\n",
    "        except:\n",
    "            errorlst.append(u)\n",
    "            print('采集数据失败，失败网址为',u)\n",
    "\n",
    "    print(12345)    \n",
    "    datadf = pd.DataFrame(datalst)\n",
    "\n",
    "    datadf.to_excel(r'F:\\I_love_learning\\junior\\数据挖掘与数据仓库\\课程设计\\dataxiaoqu.xlsx')\n",
    "\n",
    "\n",
    "'''\n",
    "ui = 'https://tj.lianjia.com/ershoufang'\n",
    "ri = requests.get(url=ui,headers = dic_h, cookies = dic_c)\n",
    "position = re.search(r\"resblockPosition\",ri.text)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
